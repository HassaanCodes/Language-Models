{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2bcebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classic PyTorch modules we'll need\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9537e155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the dataset, which is a list of names, with a name per line\n",
    "\n",
    "with open('names.txt', 'r', encoding = 'utf-8') as f:\n",
    "    names = f.read().splitlines()\n",
    "\n",
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e971df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the vocab of characters, and the mappings between characters and integers\n",
    "\n",
    "vocab = ['.'] + sorted(list(set(''.join(names))))\n",
    "vocab_len = len(vocab)\n",
    "itoc = {i:c for i, c in enumerate(vocab)}\n",
    "ctoi = {c:i for i, c in itoc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55fa70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset of bigrams\n",
    "\n",
    "x = []  # training set\n",
    "y = []  # correct outputs for the training set\n",
    "\n",
    "for name in names:\n",
    "    \n",
    "    word =  '.' + name + '.'\n",
    "    \n",
    "    for ch1, ch2 in zip(word, word[1:]):\n",
    "        \n",
    "        idx1 = ctoi[ch1]\n",
    "        idx2 = ctoi[ch2]\n",
    "        \n",
    "        x.append(idx1)\n",
    "        y.append(idx2)\n",
    "\n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7078d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = vocab_len\n",
    "g = torch.Generator().manual_seed(1869)\n",
    "inputs = F.one_hot(x, num_classes = vocab_len).float()\n",
    "W = torch.randn((vocab_len, hidden_neurons), generator = g, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd5c9e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8659188747406006\n",
      "2.676997423171997\n",
      "2.5712695121765137\n",
      "2.5346262454986572\n",
      "2.5170304775238037\n",
      "2.507004976272583\n",
      "2.5005927085876465\n",
      "2.4961941242218018\n",
      "2.4930431842803955\n",
      "2.490718364715576\n",
      "2.488964080810547\n",
      "2.4876129627227783\n",
      "2.4865529537200928\n",
      "2.485705614089966\n",
      "2.4850172996520996\n",
      "2.484450340270996\n",
      "2.483976125717163\n",
      "2.4835760593414307\n",
      "2.483234405517578\n",
      "2.482940673828125\n",
      "2.4826862812042236\n",
      "2.48246431350708\n",
      "2.482269525527954\n",
      "2.482097864151001\n",
      "2.4819464683532715\n",
      "2.4818115234375\n",
      "2.481691837310791\n",
      "2.4815850257873535\n",
      "2.4814891815185547\n",
      "2.481403112411499\n",
      "2.48132586479187\n",
      "2.4812557697296143\n",
      "2.4811933040618896\n",
      "2.481135845184326\n",
      "2.4810843467712402\n",
      "2.4810373783111572\n",
      "2.480994701385498\n",
      "2.480955123901367\n",
      "2.480919361114502\n",
      "2.480886697769165\n",
      "2.4808566570281982\n",
      "2.4808287620544434\n",
      "2.4808032512664795\n",
      "2.4807796478271484\n",
      "2.48075795173645\n",
      "2.4807376861572266\n",
      "2.4807186126708984\n",
      "2.480701446533203\n",
      "2.480684995651245\n",
      "2.480670213699341\n"
     ]
    }
   ],
   "source": [
    "tr_iter = 500\n",
    "num_samples = len(inputs)\n",
    "lre = 50\n",
    "reg_p = 0.01\n",
    "\n",
    "for i in range(tr_iter):\n",
    "    \n",
    "    logits = inputs @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(dim = -1, keepdims = True)\n",
    "    loss = -probs[torch.arange(num_samples), y].log().mean() + reg_p * (W**2).mean()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())\n",
    "    \n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    W.data += -lre * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e7a6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(c, num_chars = 10):\n",
    "    \n",
    "    idx = ctoi[c]\n",
    "    out = [c]\n",
    "    \n",
    "    for i in range(num_chars):\n",
    "        inp = F.one_hot(torch.tensor(idx), num_classes = vocab_len).float()\n",
    "        logits = inp @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(dim = -1, keepdims = True)\n",
    "        \n",
    "        idx = torch.multinomial(probs, num_samples = 1, generator = g).item()\n",
    "        out.append(itoc[idx])\n",
    "        \n",
    "        if idx == 0:\n",
    "            break\n",
    "        \n",
    "    print(''.join(out))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "634f3f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beyle.\n"
     ]
    }
   ],
   "source": [
    "generate('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c31a089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ae.\n",
      "aansorarysa\n",
      "bassin.\n",
      "chi.\n",
      "den.\n",
      "elrae.\n",
      "fuwaynaryk.\n",
      "gens.\n",
      "hiprileofac\n",
      "idhereylie.\n",
      "jbeeelle.\n",
      "kahnahrsa.\n",
      "lynnalitadr\n",
      "mtiklyacysi\n",
      "naryl.\n",
      "onn.\n",
      "peita.\n",
      "quezelllyae\n",
      "racaramerif\n",
      "shie.\n",
      "then.\n",
      "uda.\n",
      "varuwbadze.\n",
      "wbarayeossh\n",
      "x.\n",
      "ysha.\n",
      "zanaleliera\n"
     ]
    }
   ],
   "source": [
    "for ch in vocab:\n",
    "    generate(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab80696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
